{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "    /* DOWNLOAD COMPUTER MODERN FONT JUST IN CASE */\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "\n",
       "    /* GLOBAL TEXT FONT */\n",
       "    div#notebook,\n",
       "    div.output_area pre,\n",
       "    div.output_wrapper,\n",
       "    div.prompt {\n",
       "      font-family: Times new Roman, monospace !important;\n",
       "    }\n",
       "\n",
       "    /* CENTER FIGURE */\n",
       "    .output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    /* LINK */\n",
       "    a {\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H1 */\n",
       "    h1 {\n",
       "        font-size: 42px !important;\n",
       "        text-align: center;\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h2 {\n",
       "        font-size: 32px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h3 {\n",
       "        font-size: 24px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h4 {\n",
       "        font-size: 20px !important;\n",
       "    }\n",
       "\n",
       "    /* PARAGRAPH */\n",
       "    p {\n",
       "        font-size: 16px !important;\n",
       "        text-align: center;\n",
       "    }\n",
       "\n",
       "    /* LIST ITEM */\n",
       "    li {\n",
       "        font-size: 16px !important;\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../../common/import_all.py\n",
    "\n",
    "from common.setup_notebook import set_css_style, setup_matplotlib, config_ipython\n",
    "\n",
    "config_ipython()\n",
    "setup_matplotlib()\n",
    "set_css_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "Feature engineering is the process of transforming the input data into useful representation for your model to learn from. The process is usually man-driven, in that there isn't a one-recipe-fits-all and you have to apply your knowledge domain about the problems you're trying to solve in order to decide how to encode your features. \n",
    "The way you can engineer the features of a model will also vastly depend on the type and quality of data you have in the first place.\n",
    "\n",
    "Feature engineering is about what you calculate on your data to make for the best representation of the problem, that can solve it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some techniques for known problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature hashing\n",
    "\n",
    "Feature hasing is a trick used to save space and to efficiently retrieve features in memory. What you do is applying a has function to the features and use their hash values as indices of a vector used to store all feature values. It is particularly useful in problem with large number of features. \n",
    "\n",
    "For instance, feature *A* gets hashed into 56, so it is index 56 of the vector to be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "One-hot encoding is a procedure often used to transform categorical variables into numerical representations in order to use them as features in a model. The name is borrowed from the fact that *one-hot* are groups of bits where there is only a 1 and all the rest is 0. On the flip side, *one-cold* are bits where there is only a 0 among 1's. What you do to one-hot encode your variable is consider all the states in which it can be, use as many bits as there are states and for each different state you light up one of the bits. The table here reports the binary numbers 0-7 (decimal and binary representations given) encoded in a one-hot fashion: you have 8 states, so the one-hot representations is a string of 8 bits, and for each number you light up the corresponding one with a 1 while keeping all rest as 0.\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <th>**Decimal**</th><th>**Binary**</th><th>**One-hot**</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td><td>000</td><td>00000001</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td><td>001</td><td>00000010</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td><td>010</td><td>00000100</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td><td>011</td><td>00001000</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td><td>100</td><td>00010000</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td><td>101</td><td>00100000</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td><td>110</td><td>01000000</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td><td>111</td><td>10000000</td> \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Let's do an example with a proper categorical variable. Let's say one of the features you have is the status of the weather, and that it can take any of three states: sunny, cloudy, rainy. Using one-hot, you would encode it as\n",
    "\n",
    "| Weather status        | One-hotted  |\n",
    "| ------------- |:-------------:| \n",
    "| sunny     | 001 | \n",
    "| cloudy    | 010      |\n",
    "| rainy     | 100      |\n",
    "\n",
    "At the end, from one feature with 3 states, you end up with 3 features. This procedure adds dimensionality because there will be one feature per each of the states of the categorical variable, containing either a 0 pr a 1. In general, we go from $n$ observations in $d$ values to $d$ binary variables with $n$ observations each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
