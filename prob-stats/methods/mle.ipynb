{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "    /* DOWNLOAD COMPUTER MODERN FONT JUST IN CASE */\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "\n",
       "    /* GLOBAL TEXT FONT */\n",
       "    div#notebook,\n",
       "    div.output_area pre,\n",
       "    div.output_wrapper,\n",
       "    div.prompt {\n",
       "      font-family: Times new Roman, monospace !important;\n",
       "    }\n",
       "\n",
       "    /* CENTER FIGURE */\n",
       "    .output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    /* LINK */\n",
       "    a {\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H1 */\n",
       "    h1 {\n",
       "        font-size: 42px !important;\n",
       "        text-align: center;\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h2 {\n",
       "        font-size: 32px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h3 {\n",
       "        font-size: 24px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h4 {\n",
       "        font-size: 20px !important;\n",
       "    }\n",
       "\n",
       "    /* PARAGRAPH */\n",
       "    p {\n",
       "        font-size: 16px !important;\n",
       "        text-align: center;\n",
       "    }\n",
       "\n",
       "    /* LIST ITEM */\n",
       "    li {\n",
       "        font-size: 16px !important;\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../../common/import_all.py\n",
    "\n",
    "from common.setup_notebook import set_css_style, setup_matplotlib, config_ipython\n",
    "config_ipython()\n",
    "setup_matplotlib()\n",
    "set_css_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Maximum Likelihood Estimation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you have a statistical model, that is, a mathematical description of your data which depends on some parameters $\\theta$. The *likelihood function*, usually indicated as $\\mathcal{L}$, is a function of these parameters and represents the probability of observing evidence (observed data) $E$ given said parameters:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = P(E \\ | \\  \\theta)\n",
    "$$\n",
    "\n",
    "Because it is a function of the parameters given the outcome, you write\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta \\  | \\ E) = P(E \\ | \\  \\theta)\n",
    "$$\n",
    "\n",
    "The difference between *probability* and *likelihood* is quite subtle in that in common language they are be casually swapped, but they represent different things. The probability mesaures the outcomes observed as a function of the parameters $\\theta$ of the underlying model. But in reality $\\theta$ are unknown and in fact, we go through the reverse process: estimating the parameters given the evidence we observe. For this, we use the likelihood, which is defined as above because we maximise it in such a way to respond to the equality above. This is exactly what the ML estimation does, as per below.\n",
    "\n",
    "Bear in mind that the likelihood is a function of $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MLE method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Maximum Likelihood Estimation (MLE) is a procedure to find the parameters of a statistical model via the maximisation of the likelihood so as to maximise the agreement between the model and the observed data.\n",
    "\n",
    "The maximisation of the likelihood is usually performed via the maximisation of its logarithm as it is much more convenient; the logarithm is a monotonic function so the procedure is legit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: a Bernoulli distribution\n",
    "\n",
    "The likelihood function for a [Bernoulli distribution](../distributions-measures/famous-distributions.ipynb#Bernoulli)  ($x_i \\in {0, 1}$) is, for parameter $p$: \n",
    " \n",
    "\\begin{align}\n",
    "\\mathcal{L}(x_1, x_2, \\ldots, x_n \\ | \\ p) &= P(X_1 = x_1, X_2 = x_2, \\ldots, X_n = x_n \\ | \\ p) \\\\\n",
    "&= p^{x_1}(1-p)^{1-x_1} \\cdot \\ldots \\cdot p^{x_n}(1-p)^{1-x_n} \\\\\n",
    "&= p^{\\sum_i x_i}(1-p)^{\\sum_i(1-x_i)} \\\\\n",
    "&=  p^{\\sum_i x_i}(1-p)^{n -\\sum_i x_i}\n",
    "\\end{align}\n",
    "\n",
    "so that if we take the logarithm, we get\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L} = \\sum_i x_i \\log p + \\Big(n - \\sum_i x_i\\Big) \\log (1-p) \\ .\n",
    "$$\n",
    "\n",
    "To maximise it, we compute and nullify the first derivative\n",
    "\n",
    "$$\n",
    "\\frac{d \\log \\mathcal{L}}{d p} = \\frac{\\sum_i x_i}{p} - \\frac{n - \\sum_i x_i}{1-p} = 0\n",
    "$$\n",
    "\n",
    "which leads to\n",
    "\n",
    "$$\n",
    "\\sum_i x_i - p \\sum_i x_i = np - p \\sum_i x_i\n",
    "$$\n",
    "\n",
    "and finally to\n",
    "\n",
    "$$\n",
    "p = \\frac{\\sum_i x_i}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: estimating the best mean of some data\n",
    "\n",
    "This example is reported from [[here]](#2). Let us assume we know the weights of women are normally distributed with a mean $\\mu$ and standard deviation $\\sigma$. A random sample of $10$ women is (in pounds):\n",
    "\n",
    "$$\n",
    "115, 122, 130, 124, 149, 160, 152, 138, 149, 180\n",
    "$$\n",
    "\n",
    "We want to estimate $\\mu$. We know\n",
    "\n",
    "$$\n",
    "P(x_i ; \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{- \\frac{(x_i - \\mu)^2}{2 \\sigma^2}}\n",
    "$$\n",
    "\n",
    "The likelihood is (note that the $X_i$ are independent)\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(x_i | \\mu, \\sigma) &= P(X_1=x_1, \\ldots, X_n=x_n)  \\\\\n",
    "&= \\Pi_i p(x_i; \\mu \\sigma) \\\\\n",
    "&= \\sigma^n (2 \\pi)^{-n/2} e^{- \\frac{1}{2 \\sigma^2} \\sum_i (x_i - \\mu)^2}\n",
    "\\end{align}\n",
    "\n",
    "Now, again it is easier to work with the logarithm:\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L} = -n \\log \\sigma \\frac{n}{2} \\log 2 \\pi - \\frac{1}{2 \\sigma^2} \\sum_i (x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "so that \n",
    "\n",
    "$$\n",
    "\\frac{d \\log \\mathcal{L}}{d \\mu} = -\\frac{1}{2 \\sigma^2} 2 \\sum_i (x_i - \\mu) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_i x_i - n \\mu = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{\\sum_i x_i}{n}\n",
    "$$\n",
    "\n",
    "and so the maximum likelihood estimate for a given sample is 142.2 and we can could do the same to estimate $\\sigma$, obtaining (can be proven through second derivative that it is a maximum)\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{\\sum_i (x_i - \\mu)^2}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. <a name=\"cv\"></a> [Cross Validated on the difference between Probability and Likelihood](https://stats.stackexchange.com/questions/2641/what-is-the-difference-between-likelihood-and-probability)\n",
    "2. <a name=\"mle\"></a> [Some examples here](https://onlinecourses.science.psu.edu/stat414/node/191)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
