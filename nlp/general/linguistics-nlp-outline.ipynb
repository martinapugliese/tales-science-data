{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "    /* DOWNLOAD COMPUTER MODERN FONT JUST IN CASE */\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "\n",
       "    /* GLOBAL TEXT FONT */\n",
       "    div#notebook,\n",
       "    div.output_area pre,\n",
       "    div.output_wrapper,\n",
       "    div.prompt {\n",
       "      font-family: Times new Roman, monospace !important;\n",
       "    }\n",
       "\n",
       "    /* CENTER FIGURE */\n",
       "    .output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    /* LINK */\n",
       "    a {\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H1 */\n",
       "    h1 {\n",
       "        font-size: 42px !important;\n",
       "        text-align: center;\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h2 {\n",
       "        font-size: 32px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h3 {\n",
       "        font-size: 24px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h4 {\n",
       "        font-size: 20px !important;\n",
       "    }\n",
       "\n",
       "    /* PARAGRAPH */\n",
       "    p {\n",
       "        font-size: 16px !important;\n",
       "        text-align: center;\n",
       "    }\n",
       "\n",
       "    /* LIST ITEM */\n",
       "    li {\n",
       "        font-size: 16px !important;\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../../common/import_all.py\n",
    "\n",
    "from common.setup_notebook import set_css_style\n",
    "set_css_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some linguistics (a glossary) and an outline of (some) tasks in NLP\n",
    "\n",
    "This document collects some definitions of important linguistic concepts used in NLP. A good book for an overview of NLP and introduction to the tecniques is [[1]](#nlp-python). Also, an outline of tasks in NLP, which are then detailed elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little linguistics glossary\n",
    "\n",
    "### Antonyms & Synonyms\n",
    "\n",
    "**Antonyms** are words with opposite semantic meaning; **synonyms** are words with the same semantic meaning.\n",
    "\n",
    "*Examples*:\n",
    "\n",
    "* beautiful/ugly (**A**); beatiful/pretty (**S**)\n",
    "* big/small (**A**); big/large (**S**)\n",
    "\n",
    "### Collocation\n",
    "\n",
    "A **collocation** is a series of words which, in a text, occurs more often than it would by simple chance. Phrasal verbs in English are good examples.\n",
    "\n",
    "*Examples*:\n",
    "\n",
    "* white wine\n",
    "* go out\n",
    "* come in\n",
    "* ...\n",
    "\n",
    "### Concordance\n",
    "\n",
    "The **concordance** of a word (or phrase) is a list of all occurrences and contexts of the given word (or phrase) in a corpus. \n",
    "\n",
    "### Context-free grammar\n",
    "\n",
    "A context-free grammar, shortened CFG, is a grammar paradigm invented by Chomsky in the 1950s to define the structure of sentences in a formal language, in the sense that it's a set of rules describing all possible elements of the language. Specifically, a CFG contains\n",
    "\n",
    "* a list of syntactic categories for words\n",
    "* a set of rules \n",
    "\n",
    "### Corpus\n",
    "\n",
    "A **corpus** is a collection of texts, it can be generalistic (not topic-based) or specialistic. One example is the Corpus of Historical American English, or [CoHA](http://corpus.byu.edu/coha/) which at the time of writing is the largest existing corpus for the English language in history.\n",
    "\n",
    "### The Brown Corpus\n",
    "\n",
    "Compiled in the 1960s at Brown University, it is the first appeared digital corpus of the (American) English language.\n",
    "\n",
    "###Â Dispersion plot\n",
    "\n",
    "<img src=\"../../imgs/words-dispersion-plot.jpg\" width=\"500\" align=\"right\" style=\"margin:0px 50px\"/>\n",
    "\n",
    "Is a plot that, starting from where a text starts, displays where each word appears, giving an idea of both how often it is present but also how far from the etxt start it is and with which constancy.\n",
    "\n",
    "### Entailment\n",
    "\n",
    "**Entailment** is logical consequence. A sentence is entailed by another one if it logically follows it.\n",
    "\n",
    "*Examples*:\n",
    "\n",
    "* I woke up. I am awake. \n",
    "* He sleeps. He snores. (*he cannot snore without sleeping*)\n",
    "\n",
    "### Some famous exemplar sentences\n",
    "\n",
    "#### \"Colourless green ideas sleep furiously\"\n",
    "\n",
    "A sentence by N Chomsky from his book *Syntactic structures*, released in 1957, it is an example of a sentence which is grammatically admissible but totally non-sensical. \n",
    "\n",
    "#### \"Buffalo buffalo buffalo buffalo buffalo buffalo buffalo buffalo\"\n",
    "\n",
    "This is a grammatically correct sentence which can be interpreted differently depending on how it gets parsed. It is taken from D Borgmann's *Beyond Language: Adventures in Word and Thought*, 1967.\n",
    "\n",
    "The word \"buffalo\" can mean any of three things:\n",
    "\n",
    "* the animal\n",
    "* the city in the state of New York\n",
    "* a verb which means \"to intimidate\"\n",
    "\n",
    "With this, one of the possible parses would read *the buffalo from Buffalo that the buffalo from Buffalo intimidate, intimidate (other) buffalo from Buffalo*\n",
    "\n",
    "### Hapax Legomenon\n",
    "\n",
    "An **hapax legomenon** is a word or expression which appears only once in a text.\n",
    "\n",
    "### Homophones\n",
    "\n",
    "**Homophones** are words with the same pronunciation but different meaning.\n",
    "\n",
    "### Hypernyms & Hyponyms\n",
    "\n",
    "An word $w_1$ is a **hypernym** of another word $w_2$ if $w_2$ is a kind of $w_1$, that is, if there is a downward hierarchical relation from $w_1$ to $w_2$.\n",
    "\n",
    "*Examples*:\n",
    "\n",
    "* \"mammal\" is an hypernym of \"kangaroo\"\n",
    "* \"food\" is an hypernym of \"pasta\"\n",
    "\n",
    "On the other hand, a word $w_1$ is an **hyponym** of a word $w_2$ if the hierarchical relationship is reversed, that is, if $w_1$ is contained in the concept of $w_2$.\n",
    "\n",
    "*Examples*:\n",
    "\n",
    "* \"carrot\" is an hyponym of \"vegetable\"\n",
    "* \"cotton\" is an hyponym of \"textile\"\n",
    "\n",
    "### Meronyms & Holonyms\n",
    "\n",
    "A word $w_1$ is a **meronym** of a word $w_2$ if it describes something which is a constituent part of it.\n",
    "\n",
    "*Examples*:\n",
    "\n",
    "* \"toe\" is a meronym of \"foot\"\n",
    "* \"door\" is a meronym of \"house\"\n",
    "\n",
    "\n",
    "On the other hand, a **holonym** is the opposite concept: a word which describes the whole thing.\n",
    "\n",
    "*Examples*:\n",
    "\n",
    "* \"flower\" is a holonym of \"petal\"\n",
    "* \"shirt\" is a holonym of \"button\"\n",
    "\n",
    "### Noun Phrase (NP)\n",
    "\n",
    "The NP is a phrase containing a noun or pronoun as the head, or a group of tokens with noun function. It can be replaced with a single pronoun without loss of grammatical validity.\n",
    "\n",
    "*Examples* (NP highlighted in **bold**):\n",
    "\n",
    "* The **school** is there.\n",
    "* The **cranberry-based yoghurt** is delicious for **young children**.\n",
    "* There can be **several noun phrases** in **a single sentence**.\n",
    "* **He** saw **someone**.\n",
    "\n",
    "### Stem & Lemma\n",
    "\n",
    "Both the processes of stemming and lemmatising a word refer to reducing it to the mother root of it, so that, say *cats* and *cat* would be comsidered the same. But they slightly differ. The process of *stemming* a word is a very rough and heuristic one, which cuts the end based on some given rules (for instance, it assumes an ending in -s for an English word must indicate a plural form in the case of a noun and a third person inflection in the case of a verb, so chops it); the process of *lemmatising*  a word is a bit more sophisticated, uses morphology and grammar to decide when and what to cut, mapping the word to its very root vocabulary form. For instance, the lemma for *better* is *good* and stemming wouldn't catch it.\n",
    "\n",
    "Have a read a this great page [[2]](#stanford) from the Stanford NLP group on the topic, which is enriched with examples.\n",
    "\n",
    "### Stopwords\n",
    "\n",
    "Stopwords are those words in natural language which carry no own meaning and serve the purpose of connecting other words together to create grammatical sentences. They are essential components of grammar and needed for effective communication, but do not have semantic significance. Best examples are articles (\"the\", \"a\", ...), personal pronouns (\"I\", \"me\", \"you\", ...) or prepositions (\"in\", \"on\", \"to\", ...). Usually modal verbs and auxiliaries are there as well. \n",
    "\n",
    "\n",
    "### Synset\n",
    "\n",
    "A **synset** (synonym set) is a group of synonyms.\n",
    "\n",
    "### Tokens & Types\n",
    "\n",
    "A **token** is the instace of a concept, while the **type** is the word representing the overarching concept. \n",
    "\n",
    "For nouns, they can be singular and plural: the token would represent any occurrence of the word while the type the stemmed version of it, so that singular and plural are collapsed into the same type.\n",
    "\n",
    "For verbs, they can be conjugated in all tenses, so that each inflected verb is a token of the same type. Similarly to all other grammatical categories.\n",
    "\n",
    "Sentence *\"The cat chases the mouse, cats chase mice\"* contains tokens [*\"the\", \"cat\", \"chases\", \"the\", \"mouse\", \"cats\", \"chase\", \"mice\"*] and types [*\"the\", \"cat\", \"chase\", \"the\", \"mouse\", \"cat\", \"chase\", \"mice\"*], so the number of unique types is smaller than the number of unique tokens.\n",
    "\n",
    "### Treebank\n",
    "\n",
    "A treebank corpus parsed for syntactic structure, that is, one that contains information about the parts of speech and the sentence structure. The first created one is the Penn Treebank, dating back from the early 1990s and created at the University of Pennsylvania. \n",
    "\n",
    "### WordNet\n",
    "\n",
    "WordNet is a database for synsets of the English language. It started being compiled at the University of Princeton in 1985 and is available in NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An outline of tasks in NLP\n",
    "\n",
    "### POS tagging\n",
    "\n",
    "It is the process of automatically identifying the POS (*part of speech*) of tokens in a text and it is performed through the use of a tagger using info from the context of the word. \n",
    "\n",
    "### Stemming and Lemmatisation\n",
    "\n",
    "The two tasks refer to the linguistic difference between stem and lemma.\n",
    "\n",
    "Stemming is a heuristic way of chopping off the end of a word to isolate its root; lemmatisation is a dictionary and grammar-based method aimed at isolating the real mother lemma the word belongs to.\n",
    "\n",
    "### Text normalisation\n",
    "\n",
    "Text normalisation is the comprehensive name for all those sorts of operations on text aimed at cleaning it for analysis, like lowering the case, removing punctuation and so on.\n",
    "\n",
    "### Tokenisation\n",
    "\n",
    "It is the task of splitting text into linguistic units. The simplest method is to use whitespace to separate words in a sentence, for instance, but there can be more sophisticated ways as this doesn't work well for things like phrasal verbs, for instance. In any case there is no one-suits-all solution.\n",
    "\n",
    "### Word-sense disambiguation\n",
    "\n",
    "It the problem (which is still an open problem), started being researched in the 1940s, of detecting the right meaning of a word given the context. It is tackled either via dictionary-based methods or Machine Learning. \n",
    "\n",
    "### Word alignment\n",
    "\n",
    "It is the task of aligning corresponding parts of the same sentence in different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. <a name=\"nlp-python\"></a> S Bird, E Klein, E Loper, [**Natural Language Processing with Python**](http://www.nltk.org/book_1ed/), *O'Reilly*, 2009\n",
    "2. <a name=\"stanford\"></a> [The Stanford NLP group on stemming and lemmatising](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
