{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "    /* DOWNLOAD COMPUTER MODERN FONT JUST IN CASE */\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "\n",
       "    /* GLOBAL TEXT FONT */\n",
       "    div#notebook,\n",
       "    div.output_area pre,\n",
       "    div.output_wrapper,\n",
       "    div.prompt {\n",
       "      font-family: Times new Roman, monospace !important;\n",
       "    }\n",
       "\n",
       "    /* CENTER FIGURE */\n",
       "    .output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    /* LINK */\n",
       "    a {\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H1 */\n",
       "    h1 {\n",
       "        font-size: 42px !important;\n",
       "        text-align: center;\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h2 {\n",
       "        font-size: 32px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h3 {\n",
       "        font-size: 24px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h4 {\n",
       "        font-size: 20px !important;\n",
       "    }\n",
       "\n",
       "    /* PARAGRAPH */\n",
       "    p {\n",
       "        font-size: 16px !important;\n",
       "        text-align: center;\n",
       "    }\n",
       "\n",
       "    /* LIST ITEM */\n",
       "    li {\n",
       "        font-size: 16px !important;\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../../common/import_all.py\n",
    "\n",
    "from common.setup_notebook import set_css_style, setup_matplotlib, config_ipython\n",
    "config_ipython()\n",
    "setup_matplotlib()\n",
    "set_css_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is\n",
    "\n",
    "Hadoop is an open source framework to store data and run applications. The original idea came to D. Cutting and M. Cafarella around 2002 after reading a paper by Google on MapReduce [[1]](#mr). \n",
    "\n",
    "Hadoop consists of its own file system, the *HDFS*, and its computation framework, *MapReduce*. We shall now briefly describe them both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The HDFS\n",
    "\n",
    "<img src=\"../../imgs/hdfs.pdf\" align=\"left\" width=\"400\" style=\"margin:0px 50px\"/>\n",
    "\n",
    "For data storage, Hadoop uses the *HDFS* (Hadoop Distributed File System), which splits data into blocks. A cluster is composed by several nodes and the HDFS manages their relations. The figure illustrates how the HDFS works. Each block of data, whose maximum size is 64  MB, is stored in a node in the cluster (*data nodes*), plus there is a *name node* which keeps the metadata, knowing what is in each block. \n",
    "\n",
    "Now, because nodes may fail, Hadoop replicates each block of data 3 times and places blocks of data in different nodes, so that effectively each node contains multiple blocks, each block then appearing thrice in total and over 3 nodes (*e.g.*, node 1 contains blocks 1, 3 and 7), by randomly assigning them.  The name node knows what is in each block and that blocks are replicated and is copied on a NFS (*Network File System*) in order to have a copy in case of failure of the name node.\n",
    "\n",
    "Note that the HDFS as a file system is used way beyond Hadoop alone, for example in [Spark](spark.ipynb), which is usually placed on top of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Processing: the MapReduce paradigm\n",
    "\n",
    "This programming model was originally proprietary of Google, now used extensively in the world of computation over large datasets. It consists of the two main complementary operations of *map* and *reduce*, linked together by the intermediate state of *shuffle & sort*.\n",
    "\n",
    "<img src=\"../../imgs/hadoop-chunks.pdf\" align=\"left\" width=\"300\" style=\"margin:0px 50px\"/>\n",
    "\n",
    "A large file is broken into chunks, to be processed in parallel\n",
    "\n",
    "1. *map*:  the *mappers* are small programs which work in parallel, producing intermediate records as (key, value) pairs;\n",
    "2. *shuffle & sort*:  the shuffle operation moves the intermediate records produced by the mappers to the reducers, which will organise the values into sorted records;\n",
    "3. *reduce*: the *reducers* take one pile or records at a time and list all the values for each key, writing the results.\n",
    "\n",
    "### An example\n",
    "\n",
    "This example has been inspired and reworked from [[2]](#udacity), the full course is warmly recommended. \n",
    "\n",
    "A retailer has an inventory of all sales it makes, and wants to know the total sales for each of its stores. One record in the inventory/databaae contains this information:\n",
    "\n",
    "* the date of the sale\n",
    "* the store where the sale happened\n",
    "* the item sold\n",
    "* the amount item has been sold at\n",
    "\n",
    "<img src=\"../../imgs/hadoop-mappers.pdf\" align=\"right\" width=\"300\" style=\"margin:0px 50px\"/>\n",
    "\n",
    "**The map phase**: the mappers take some rows each and create cards with (key, value) pairs where a key is the store and a value is the amount.  They create a pile of values for each same key (same store), see figure. This obviously means that different mappers can create piles for the same stores.\n",
    "\n",
    "**The shuffle & sort phase**: records (stores) are alphabetically sorted and assigned to reducers.\n",
    "\n",
    "**The reduce phase**: now, each reducer will be responsible for a specific store.  Reducers will read all the piles of values for their assigned store and will create a big pile for it. At that point, they will go through the  pile and add u all the amounts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. <a name=\"mr\"></a> J Dean, S Ghemawat, [MapReduce: Simplified Data Processing on Large Clusters](http://static.googleusercontent.com/media/research.google.com/en/us/archive/mapreduce-osdi04.pdf), *Communications of the ACM*, 51.1, 2008.\n",
    "2. <a name=\"udacity\"></a> [A Udacity fun and practical course on Hadoop and MapReduce](https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
